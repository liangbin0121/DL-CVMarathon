{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"Day015_Cifar_HW.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hOZ29FShiycD","colab_type":"text"},"source":["## 『本次練習內容』\n","#### 運用這幾天所學觀念搭建一個CNN分類器"]},{"cell_type":"markdown","metadata":{"id":"G4H5nNwMiycE","colab_type":"text"},"source":["## 『本次練習目的』\n","  #### 熟悉CNN分類器搭建步驟與原理\n","  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"]},{"cell_type":"code","metadata":{"id":"7ti7fN4hiycE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594718675638,"user_tz":-480,"elapsed":2893,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"3fb77795-3afb-469a-e68c-00a328c1faa5"},"source":["from keras.models import Sequential\n","from keras.layers import Convolution2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import BatchNormalization\n","from keras.layers import Activation\n","from keras.datasets import cifar10\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.preprocessing import OneHotEncoder\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YyMZ_2AJiycI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594718679336,"user_tz":-480,"elapsed":3041,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"82ee3167-7146-4ff2-9053-4c1eb98d1aaa"},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","print(x_train.shape) #(50000, 32, 32, 3)\n","\n","## Normalize Data\n","def normalize(X_train,X_test):\n","        mean = np.mean(X_train,axis=(0,1,2,3))\n","        std = np.std(X_train, axis=(0, 1, 2, 3))\n","        X_train = (X_train-mean)/(std+1e-7)\n","        X_test = (X_test-mean)/(std+1e-7) \n","        return X_train, X_test,mean,std\n","    \n","    \n","## Normalize Training and Testset    \n","x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "],"execution_count":2,"outputs":[{"output_type":"stream","text":["(50000, 32, 32, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E2YTO1MXjv4V","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-PojtkqiycK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594718680763,"user_tz":-480,"elapsed":1287,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["## OneHot Label 由(None, 1)-(None, 10)\n","## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n","one_hot=OneHotEncoder()\n","y_train=one_hot.fit_transform(y_train).toarray()\n","y_test=one_hot.transform(y_test).toarray()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXeaBkfziycN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"status":"ok","timestamp":1594719475944,"user_tz":-480,"elapsed":955,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"887ea91b-e440-4d93-b7ef-721fdc5b652e"},"source":["\n","classifier=Sequential()\n","\n","#卷積組合  , filters =32 , kernel_size= (3,3), strides=(1, 1), padding='same'\n","##Kernel size 3*3，用32張，輸入大小32*32*3\n","classifier.add(Convolution2D(filters =32 , kernel_size= (3,3), strides=(1, 1), padding='same',input_shape=(32,32,3)))\n","#32,3,3,input_shape=(32,32,3),activation='relu''\n","classifier.add(BatchNormalization())\n","classifier.add(Activation('relu'))\n","\n","'''自己決定MaxPooling2D放在哪裡'''\n","classifier.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#卷積組合\n","#classifier.add(Convolution2D(32,3,3,input_shape=(32,32,3))) #32,3,3,input_shape=(32,32,3),activation='relu''\n","classifier.add(Convolution2D(filters =32 , kernel_size= (3,3), strides=(1, 1), padding='same')) #\n","classifier.add(BatchNormalization())\n","classifier.add(Activation('relu'))\n","\n","#flatten\n","classifier.add(Flatten())\n","\n","#FC\n","classifier.add(Dense(output_dim=100,activation='relu')) #output_dim=100,activation=relu\n","\n","#輸出\n","classifier.add(Dense(output_dim=10,activation='softmax'))\n","\n","print(classifier.summary())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 16, 16, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 16, 16, 32)        128       \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 8192)              0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 100)               819300    \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 10)                1010      \n","=================================================================\n","Total params: 830,710\n","Trainable params: 830,582\n","Non-trainable params: 128\n","_________________________________________________________________\n","None\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZswF9miNn3q3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594720705138,"user_tz":-480,"elapsed":1004135,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"ef859c7d-2da9-4bdd-8aac-abdcd7f4c16c"},"source":["#超過兩個就要選categorical_crossentrophy\n","classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","classifier.fit(x_train,y_train,batch_size=100,epochs=100)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","50000/50000 [==============================] - 16s 324us/step - loss: 1.3322 - accuracy: 0.5256\n","Epoch 2/100\n","50000/50000 [==============================] - 10s 206us/step - loss: 0.9723 - accuracy: 0.6579\n","Epoch 3/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.8451 - accuracy: 0.7033\n","Epoch 4/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.7676 - accuracy: 0.7332\n","Epoch 5/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.7042 - accuracy: 0.7529\n","Epoch 6/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.6444 - accuracy: 0.7750\n","Epoch 7/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.5977 - accuracy: 0.7896\n","Epoch 8/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.5487 - accuracy: 0.8071\n","Epoch 9/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.5075 - accuracy: 0.8234\n","Epoch 10/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.4653 - accuracy: 0.8380\n","Epoch 11/100\n","50000/50000 [==============================] - 10s 200us/step - loss: 0.4316 - accuracy: 0.8491\n","Epoch 12/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.3872 - accuracy: 0.8667\n","Epoch 13/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.3577 - accuracy: 0.8744\n","Epoch 14/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.3378 - accuracy: 0.8813\n","Epoch 15/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.3066 - accuracy: 0.8921\n","Epoch 16/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.2710 - accuracy: 0.9050\n","Epoch 17/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.2641 - accuracy: 0.9061\n","Epoch 18/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.2332 - accuracy: 0.9178\n","Epoch 19/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.2199 - accuracy: 0.9232\n","Epoch 20/100\n","50000/50000 [==============================] - 10s 202us/step - loss: 0.1942 - accuracy: 0.9324\n","Epoch 21/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1769 - accuracy: 0.9384\n","Epoch 22/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1696 - accuracy: 0.9404\n","Epoch 23/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1640 - accuracy: 0.9413\n","Epoch 24/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1509 - accuracy: 0.9484\n","Epoch 25/100\n","50000/50000 [==============================] - 10s 197us/step - loss: 0.1437 - accuracy: 0.9485\n","Epoch 26/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.1259 - accuracy: 0.9570\n","Epoch 27/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1257 - accuracy: 0.9566\n","Epoch 28/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1179 - accuracy: 0.9589\n","Epoch 29/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1047 - accuracy: 0.9646\n","Epoch 30/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.1225 - accuracy: 0.9560\n","Epoch 31/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.1076 - accuracy: 0.9619\n","Epoch 32/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0837 - accuracy: 0.9716\n","Epoch 33/100\n","50000/50000 [==============================] - 10s 206us/step - loss: 0.0953 - accuracy: 0.9670\n","Epoch 34/100\n","50000/50000 [==============================] - 10s 200us/step - loss: 0.0943 - accuracy: 0.9658\n","Epoch 35/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.1046 - accuracy: 0.9629\n","Epoch 36/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0776 - accuracy: 0.9737\n","Epoch 37/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0737 - accuracy: 0.9749\n","Epoch 38/100\n","50000/50000 [==============================] - 10s 197us/step - loss: 0.0835 - accuracy: 0.9696\n","Epoch 39/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0823 - accuracy: 0.9713\n","Epoch 40/100\n","50000/50000 [==============================] - 10s 197us/step - loss: 0.0701 - accuracy: 0.9763\n","Epoch 41/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0717 - accuracy: 0.9747\n","Epoch 42/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0751 - accuracy: 0.9749\n","Epoch 43/100\n","50000/50000 [==============================] - 10s 200us/step - loss: 0.0604 - accuracy: 0.9790\n","Epoch 44/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0760 - accuracy: 0.9731\n","Epoch 45/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0641 - accuracy: 0.9784\n","Epoch 46/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0706 - accuracy: 0.9747\n","Epoch 47/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0617 - accuracy: 0.9786\n","Epoch 48/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0550 - accuracy: 0.9814\n","Epoch 49/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0619 - accuracy: 0.9792\n","Epoch 50/100\n","50000/50000 [==============================] - 10s 201us/step - loss: 0.0627 - accuracy: 0.9781\n","Epoch 51/100\n","50000/50000 [==============================] - 10s 200us/step - loss: 0.0543 - accuracy: 0.9810\n","Epoch 52/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0602 - accuracy: 0.9791\n","Epoch 53/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0525 - accuracy: 0.9817\n","Epoch 54/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0532 - accuracy: 0.9816\n","Epoch 55/100\n","50000/50000 [==============================] - 10s 200us/step - loss: 0.0670 - accuracy: 0.9772\n","Epoch 56/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0543 - accuracy: 0.9810\n","Epoch 57/100\n","50000/50000 [==============================] - 10s 200us/step - loss: 0.0398 - accuracy: 0.9860\n","Epoch 58/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0450 - accuracy: 0.9848\n","Epoch 59/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0700 - accuracy: 0.9759\n","Epoch 60/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0423 - accuracy: 0.9857\n","Epoch 61/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0409 - accuracy: 0.9859\n","Epoch 62/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0500 - accuracy: 0.9830\n","Epoch 63/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0469 - accuracy: 0.9831\n","Epoch 64/100\n","50000/50000 [==============================] - 10s 203us/step - loss: 0.0445 - accuracy: 0.9839\n","Epoch 65/100\n","50000/50000 [==============================] - 10s 201us/step - loss: 0.0463 - accuracy: 0.9839\n","Epoch 66/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0592 - accuracy: 0.9797\n","Epoch 67/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0460 - accuracy: 0.9844\n","Epoch 68/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0336 - accuracy: 0.9886\n","Epoch 69/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0495 - accuracy: 0.9826\n","Epoch 70/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0454 - accuracy: 0.9845\n","Epoch 71/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0471 - accuracy: 0.9839\n","Epoch 72/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0387 - accuracy: 0.9863\n","Epoch 73/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0287 - accuracy: 0.9905\n","Epoch 74/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0384 - accuracy: 0.9866\n","Epoch 75/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0537 - accuracy: 0.9815\n","Epoch 76/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0375 - accuracy: 0.9879\n","Epoch 77/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0266 - accuracy: 0.9907\n","Epoch 78/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0550 - accuracy: 0.9809\n","Epoch 79/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0410 - accuracy: 0.9862\n","Epoch 80/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0279 - accuracy: 0.9906\n","Epoch 81/100\n","50000/50000 [==============================] - 10s 202us/step - loss: 0.0311 - accuracy: 0.9895\n","Epoch 82/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0518 - accuracy: 0.9819\n","Epoch 83/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0305 - accuracy: 0.9900\n","Epoch 84/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0344 - accuracy: 0.9882\n","Epoch 85/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0384 - accuracy: 0.9872\n","Epoch 86/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0333 - accuracy: 0.9888\n","Epoch 87/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0459 - accuracy: 0.9846\n","Epoch 88/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0302 - accuracy: 0.9899\n","Epoch 89/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0313 - accuracy: 0.9890\n","Epoch 90/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0371 - accuracy: 0.9877\n","Epoch 91/100\n","50000/50000 [==============================] - 10s 197us/step - loss: 0.0330 - accuracy: 0.9891\n","Epoch 92/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0382 - accuracy: 0.9873\n","Epoch 93/100\n","50000/50000 [==============================] - 10s 200us/step - loss: 0.0346 - accuracy: 0.9886\n","Epoch 94/100\n","50000/50000 [==============================] - 10s 199us/step - loss: 0.0342 - accuracy: 0.9884\n","Epoch 95/100\n","50000/50000 [==============================] - 10s 201us/step - loss: 0.0214 - accuracy: 0.9924\n","Epoch 96/100\n","50000/50000 [==============================] - 10s 203us/step - loss: 0.0327 - accuracy: 0.9891\n","Epoch 97/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0407 - accuracy: 0.9863\n","Epoch 98/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0339 - accuracy: 0.9885\n","Epoch 99/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0314 - accuracy: 0.9891\n","Epoch 100/100\n","50000/50000 [==============================] - 10s 198us/step - loss: 0.0229 - accuracy: 0.9923\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f3bf5727d68>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"cyQEjOQeuYKq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1594720736873,"user_tz":-480,"elapsed":9247,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"5d8cee81-6a2a-482b-ab98-1bda5c5e5693"},"source":["score_train = classifier.evaluate(x_train, y_train, verbose=1)\n","print('train loss:', score_train[0])\n","print('train accuracy:', score_train[1])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["50000/50000 [==============================] - 8s 170us/step\n","train loss: 0.012845843896151055\n","train accuracy: 0.9961599707603455\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AmzoJDJjtwrI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1594720758310,"user_tz":-480,"elapsed":2270,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"5ce5b20e-c37c-4907-ab4c-7a4face13cfa"},"source":["scores_test = classifier.evaluate(x_test, y_test, verbose=1)\n","print('test loss:', scores_test[0])\n","print('test accuracy:', scores_test[1])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 2s 169us/step\n","test loss: 3.908729706954956\n","test accuracy: 0.6535000205039978\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FGDT6aG9iycP","colab_type":"text"},"source":["## 預測新圖片，輸入影像前處理要與訓練時相同\n","#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n","## 維度如下方示範"]},{"cell_type":"code","metadata":{"id":"37eknSOtiycP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1594720961866,"user_tz":-480,"elapsed":890,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"207ef3c6-b966-40b4-d59e-a60f3d32826e"},"source":["input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n","classifier.predict(input_example)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[9.1663729e-05, 1.4269936e-16, 7.5310445e-06, 9.9922454e-01,\n","        6.3538289e-04, 1.4607748e-09, 4.8214172e-10, 9.2673097e-10,\n","        4.0845720e-05, 1.8829894e-15]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":13}]}]}